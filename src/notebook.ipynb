{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Default notebook\n",
    "\n",
    "This default notebook is executed using Databricks Workflows as defined in resources/lineage_ops.job.yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bca260b-13d1-448f-8082-30b60a85c9ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Target catalog to analyze (None for all)\n",
    "CATALOG_FILTER = 'hurcy'  # e.g., \"prod_catalog\"\n",
    "\n",
    "# Similarity threshold (0.8 = only pairs with 80%+ similarity)\n",
    "SIMILARITY_THRESHOLD = 0.8\n",
    "\n",
    "# Lineage query period (days)\n",
    "DAYS_BACK = 30\n",
    "\n",
    "# Embedding provider (\"databricks\", \"openai\", \"simple\")\n",
    "EMBEDDING_PROVIDER = \"databricks\"\n",
    "\n",
    "# Result storage location\n",
    "RESULT_CATALOG = \"hurcy\"\n",
    "RESULT_SCHEMA = \"analysis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"/Workspace/Users/cinyoung.hur@databricks.com/.bundle/lineage_ops/dev/files/src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lineage_ops.main import DuplicatedTableDetector, LineageOpsConfig\n",
    "\n",
    "# Create configuration object\n",
    "config = LineageOpsConfig(\n",
    "    catalog_filter=CATALOG_FILTER,\n",
    "    days_back=DAYS_BACK,\n",
    "    similarity_threshold=SIMILARITY_THRESHOLD,\n",
    "    embedding_provider=EMBEDDING_PROVIDER\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize detector\n",
    "detector = DuplicatedTableDetector(spark, config)\n",
    "\n",
    "# Extract lineage information\n",
    "lineage_df = detector.extract_lineage()\n",
    "print(f\"Lineage events: {lineage_df.count():,}\")\n",
    "display(lineage_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common ancestors\n",
    "from lineage_ops.data_extractor import LineageExtractor\n",
    "lineage_extractor = LineageExtractor(spark)\n",
    "lineage_df = lineage_extractor.get_table_lineage(days_back=30)\n",
    "common_ancestors = lineage_extractor.find_common_ancestors(lineage_df)\n",
    "display(common_ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract schema texts\n",
    "schema_texts_df = detector.extract_schema_texts()\n",
    "print(f\"Tables to analyze: {schema_texts_df.count():,}\")\n",
    "display(schema_texts_df.limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Schema Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks Foundation Model \n",
    "from lineage_ops.schema_embedder import DatabricksFoundationModelProvider, SchemaEmbedder\n",
    "\n",
    "provider = DatabricksFoundationModelProvider(endpoint_name=\"databricks-bge-large-en\")\n",
    "embedder = SchemaEmbedder(spark, provider)\n",
    "embeddings_df = embedder.embed_schema_texts(schema_texts_df)\n",
    "display(embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity Search and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lineage_ops.similarity_analyzer import SimilarityAnalyzer\n",
    "analyzer = SimilarityAnalyzer(spark)\n",
    "# Compute cosine similarity\n",
    "# similar_pairs = analyzer.compute_cosine_similarity(embeddings_df, similarity_threshold=0.8)\n",
    "# display(similar_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use LSH for efficient large-scale search\n",
    "similar_pairs = analyzer.compute_similarity_with_lsh(embeddings_df)\n",
    "display(similar_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Duplicate Candidate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate candidates\n",
    "candidates_df = detector.find_duplicate_candidates()\n",
    "print(f\"Duplicate candidate pairs: {candidates_df.count():,}\")\n",
    "display(candidates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Generate Consolidation Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate consolidation recommendations\n",
    "recommendations_df = detector.generate_recommendations()\n",
    "display(recommendations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lineage_ops.recommendation_generator import RecommendationGenerator\n",
    "\n",
    "generator = RecommendationGenerator(spark)\n",
    "summary = generator.generate_summary_report(recommendations_df)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Analysis Results Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Duplicate table pairs found: {summary['summary']['total_duplicate_pairs_found']:,}\")\n",
    "print(f\"Estimated monthly DBU savings: ${summary['summary']['estimated_monthly_dbu_savings_usd']:,.2f}\")\n",
    "print(f\"Estimated storage savings: {summary['summary']['estimated_storage_savings_gb']:,.2f} GB\")\n",
    "print(f\"Pipelines to remove: {summary['summary']['total_pipelines_to_remove']:,}\")\n",
    "print(f\"Average similarity score: {summary['summary']['average_similarity_score']:.2%}\")\n",
    "print()\n",
    "print(\"Confidence distribution:\")\n",
    "for level, count in summary['confidence_distribution'].items():\n",
    "    print(f\"  {level}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = detector.run_full_analysis(include_visualization=True)\n",
    "\n",
    "# 결과 확인\n",
    "results[\"results\"][\"visualization\"].display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save results to Delta tables\n",
    "detector.save_results(RESULT_CATALOG, RESULT_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detailed Analysis Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detailed analysis of the most similar table pair\n",
    "top_candidate = candidates_df.first()\n",
    "\n",
    "if top_candidate:\n",
    "    print(f\"Table A: {top_candidate['table_a']}\")\n",
    "    print(f\"Table B: {top_candidate['table_b']}\")\n",
    "    print(f\"Similarity score: {top_candidate['cosine_similarity']:.2%}\")\n",
    "    print(f\"Confidence: {top_candidate['confidence_level']}\")\n",
    "    \n",
    "    # Detailed column comparison\n",
    "    from lineage_ops.data_extractor import SchemaExtractor\n",
    "    extractor = SchemaExtractor(spark)\n",
    "    \n",
    "    cols_a = extractor.get_column_metadata(top_candidate['table_a'])\n",
    "    cols_b = extractor.get_column_metadata(top_candidate['table_b'])\n",
    "    \n",
    "    print(f\"\\n{top_candidate['table_a']} columns:\")\n",
    "    display(cols_a)\n",
    "    \n",
    "    print(f\"\\n{top_candidate['table_b']} columns:\")\n",
    "    display(cols_b)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
